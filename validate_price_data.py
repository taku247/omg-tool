#!/usr/bin/env python3
"""
validate_price_data.py
======================
ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å“è³ªç¢ºèªã¨æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

åé›†ã•ã‚ŒãŸä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®ä»¥ä¸‹ã‚’æ¤œè¨¼:
- ãƒ‡ãƒ¼ã‚¿å½¢å¼ã®æ•´åˆæ€§
- ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®é€£ç¶šæ€§ã¨åŒæœŸ
- ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®å¦¥å½“æ€§ï¼ˆbid <= askç­‰ï¼‰
- æ¬ æãƒ‡ãƒ¼ã‚¿ã®ç‰¹å®š
- ã‚¢ãƒ¼ãƒ“ãƒˆãƒ©ãƒ¼ã‚¸æ©Ÿä¼šã®äºˆå‚™åˆ†æ

ä½¿ã„æ–¹:
    python validate_price_data.py --date 20250623
    python validate_price_data.py --date 20250623 --detailed
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from pathlib import Path
import argparse
import logging
from typing import Dict, List, Tuple, Optional
import sys

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class PriceDataValidator:
    """ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, data_dir: str):
        self.data_dir = Path(data_dir)
        self.exchanges = ["bybit", "hyperliquid", "gateio", "kucoin"]
        self.symbols = ["BTC", "ETH", "SOL", "XRP"]
        self.data_frames = {}
        
    def load_csv_files(self, date: str) -> Dict[str, pd.DataFrame]:
        """æŒ‡å®šæ—¥ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        logger.info(f"ğŸ“‚ {date}ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...")
        
        date_dir = self.data_dir / date
        if not date_dir.exists():
            raise FileNotFoundError(f"ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {date_dir}")
            
        for exchange in self.exchanges:
            csv_file = date_dir / f"{exchange}_prices_{date}.csv"
            
            if csv_file.exists():
                try:
                    df = pd.read_csv(csv_file)
                    df['timestamp'] = pd.to_datetime(df['timestamp'])
                    self.data_frames[exchange] = df
                    logger.info(f"âœ… {exchange}: {len(df)}è¡Œ èª­ã¿è¾¼ã¿å®Œäº†")
                except Exception as e:
                    logger.error(f"âŒ {exchange}: CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ - {e}")
            else:
                logger.warning(f"âš ï¸  {exchange}: CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                
        return self.data_frames
        
    def validate_data_format(self) -> Dict[str, Dict]:
        """ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®æ¤œè¨¼"""
        logger.info("ğŸ” ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’æ¤œè¨¼ä¸­...")
        
        required_columns = ['timestamp', 'exchange', 'symbol', 'bid', 'ask', 'last', 'mark_price']
        results = {}
        
        for exchange, df in self.data_frames.items():
            result = {
                'total_rows': len(df),
                'missing_columns': [],
                'data_types': {},
                'null_counts': {},
                'duplicate_rows': 0
            }
            
            # å¿…é ˆã‚«ãƒ©ãƒ ãƒã‚§ãƒƒã‚¯
            for col in required_columns:
                if col not in df.columns:
                    result['missing_columns'].append(col)
                else:
                    result['data_types'][col] = str(df[col].dtype)
                    result['null_counts'][col] = df[col].isnull().sum()
            
            # é‡è¤‡è¡Œãƒã‚§ãƒƒã‚¯
            result['duplicate_rows'] = df.duplicated().sum()
            
            results[exchange] = result
            
        return results
        
    def validate_price_consistency(self) -> Dict[str, Dict]:
        """ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§æ¤œè¨¼"""
        logger.info("ğŸ’° ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§ã‚’æ¤œè¨¼ä¸­...")
        
        results = {}
        
        for exchange, df in self.data_frames.items():
            result = {
                'bid_ask_violations': 0,
                'zero_prices': 0,
                'negative_prices': 0,
                'extreme_spreads': 0,
                'price_ranges': {}
            }
            
            if 'bid' in df.columns and 'ask' in df.columns:
                # bid > ask ã®ç•°å¸¸ã‚’ãƒã‚§ãƒƒã‚¯
                bid_ask_violations = (df['bid'] > df['ask']) & (df['ask'] > 0)
                result['bid_ask_violations'] = bid_ask_violations.sum()
                
                # ã‚¼ãƒ­ä¾¡æ ¼ã‚’ãƒã‚§ãƒƒã‚¯
                result['zero_prices'] = ((df['bid'] <= 0) | (df['ask'] <= 0)).sum()
                
                # è² ã®ä¾¡æ ¼ã‚’ãƒã‚§ãƒƒã‚¯
                result['negative_prices'] = ((df['bid'] < 0) | (df['ask'] < 0)).sum()
                
                # æ¥µç«¯ãªã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆ5%ä»¥ä¸Šï¼‰
                spread_pct = ((df['ask'] - df['bid']) / df['bid'] * 100)
                result['extreme_spreads'] = (spread_pct > 5.0).sum()
                
                # ã‚·ãƒ³ãƒœãƒ«åˆ¥ä¾¡æ ¼ãƒ¬ãƒ³ã‚¸
                for symbol in self.symbols:
                    symbol_data = df[df['symbol'] == symbol]
                    if len(symbol_data) > 0:
                        result['price_ranges'][symbol] = {
                            'bid_min': float(symbol_data['bid'].min()) if 'bid' in symbol_data.columns else None,
                            'bid_max': float(symbol_data['bid'].max()) if 'bid' in symbol_data.columns else None,
                            'ask_min': float(symbol_data['ask'].min()) if 'ask' in symbol_data.columns else None,
                            'ask_max': float(symbol_data['ask'].max()) if 'ask' in symbol_data.columns else None,
                            'count': len(symbol_data)
                        }
            
            results[exchange] = result
            
        return results
        
    def validate_timestamp_synchronization(self) -> Dict:
        """ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®åŒæœŸæ€§æ¤œè¨¼"""
        logger.info("â° ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®åŒæœŸæ€§ã‚’æ¤œè¨¼ä¸­...")
        
        if len(self.data_frames) < 2:
            return {"error": "åŒæœŸæ¤œè¨¼ã«ã¯2ã¤ä»¥ä¸Šã®å–å¼•æ‰€ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦"}
            
        # å…¨ãƒ‡ãƒ¼ã‚¿ã®æ™‚é–“ç¯„å›²ã‚’è¨ˆç®—
        all_timestamps = []
        for df in self.data_frames.values():
            all_timestamps.extend(df['timestamp'].tolist())
            
        if not all_timestamps:
            return {"error": "ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}
            
        min_time = min(all_timestamps)
        max_time = max(all_timestamps)
        total_duration = (max_time - min_time).total_seconds()
        
        # æ™‚é–“çª“ã§ã®åŒæœŸãƒã‚§ãƒƒã‚¯ï¼ˆ1åˆ†çª“ï¼‰
        sync_windows = self._check_synchronization_windows()
        
        result = {
            'time_range': {
                'start': min_time.isoformat(),
                'end': max_time.isoformat(),
                'duration_seconds': total_duration,
                'duration_hours': total_duration / 3600
            },
            'exchange_coverage': {},
            'synchronization_windows': sync_windows
        }
        
        # å„å–å¼•æ‰€ã®æ™‚é–“ã‚«ãƒãƒ¬ãƒƒã‚¸
        for exchange, df in self.data_frames.items():
            if len(df) > 0:
                exchange_min = df['timestamp'].min()
                exchange_max = df['timestamp'].max()
                result['exchange_coverage'][exchange] = {
                    'start': exchange_min.isoformat(),
                    'end': exchange_max.isoformat(),
                    'data_points': len(df),
                    'coverage_ratio': (exchange_max - exchange_min).total_seconds() / total_duration if total_duration > 0 else 0
                }
        
        return result
        
    def _check_synchronization_windows(self, window_minutes: int = 1) -> Dict:
        """æŒ‡å®šæ™‚é–“çª“ã§ã®åŒæœŸãƒã‚§ãƒƒã‚¯"""
        if len(self.data_frames) < 2:
            return {}
            
        # æœ€åˆã®å–å¼•æ‰€ã‚’ãƒ™ãƒ¼ã‚¹ã«ã™ã‚‹
        base_exchange = list(self.data_frames.keys())[0]
        base_df = self.data_frames[base_exchange]
        
        if len(base_df) == 0:
            return {}
            
        # æ™‚é–“çª“ã‚’ä½œæˆ
        start_time = base_df['timestamp'].min()
        end_time = base_df['timestamp'].max()
        windows = pd.date_range(start_time, end_time, freq=f'{window_minutes}T')
        
        sync_results = []
        
        for i in range(len(windows) - 1):
            window_start = windows[i]
            window_end = windows[i + 1]
            
            window_data = {}
            for exchange, df in self.data_frames.items():
                window_mask = (df['timestamp'] >= window_start) & (df['timestamp'] < window_end)
                window_data[exchange] = len(df[window_mask])
                
            sync_results.append({
                'window_start': window_start.isoformat(),
                'data_counts': window_data,
                'total_exchanges_with_data': sum(1 for count in window_data.values() if count > 0)
            })
            
        return {
            'window_minutes': window_minutes,
            'total_windows': len(sync_results),
            'windows': sync_results[:10]  # æœ€åˆã®10å€‹ã®çª“ã®ã¿è¡¨ç¤º
        }
        
    def find_arbitrage_opportunities(self, min_spread_pct: float = 0.1) -> Dict:
        """ã‚¢ãƒ¼ãƒ“ãƒˆãƒ©ãƒ¼ã‚¸æ©Ÿä¼šã®äºˆå‚™åˆ†æ"""
        logger.info(f"ğŸ“Š ã‚¢ãƒ¼ãƒ“ãƒˆãƒ©ãƒ¼ã‚¸æ©Ÿä¼šã‚’åˆ†æä¸­ï¼ˆæœ€å°ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰: {min_spread_pct}%ï¼‰...")
        
        opportunities = []
        
        # åŒä¸€ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§ã®ä¾¡æ ¼æ¯”è¼ƒ
        for symbol in self.symbols:
            symbol_opportunities = self._find_symbol_arbitrage(symbol, min_spread_pct)
            opportunities.extend(symbol_opportunities)
            
        result = {
            'total_opportunities': len(opportunities),
            'opportunities_by_symbol': {},
            'best_opportunities': sorted(opportunities, key=lambda x: x['spread_pct'], reverse=True)[:10]
        }
        
        # ã‚·ãƒ³ãƒœãƒ«åˆ¥é›†è¨ˆ
        for symbol in self.symbols:
            symbol_opps = [opp for opp in opportunities if opp['symbol'] == symbol]
            result['opportunities_by_symbol'][symbol] = {
                'count': len(symbol_opps),
                'avg_spread': np.mean([opp['spread_pct'] for opp in symbol_opps]) if symbol_opps else 0,
                'max_spread': max([opp['spread_pct'] for opp in symbol_opps]) if symbol_opps else 0
            }
            
        return result
        
    def _find_symbol_arbitrage(self, symbol: str, min_spread_pct: float) -> List[Dict]:
        """ç‰¹å®šã‚·ãƒ³ãƒœãƒ«ã®ã‚¢ãƒ¼ãƒ“ãƒˆãƒ©ãƒ¼ã‚¸æ©Ÿä¼šã‚’æ¤œç´¢"""
        opportunities = []
        
        # å„æ™‚ç‚¹ã§ã®ä¾¡æ ¼ã‚’å–å¾—
        all_prices = []
        
        for exchange, df in self.data_frames.items():
            symbol_data = df[df['symbol'] == symbol].copy()
            if len(symbol_data) > 0:
                symbol_data['exchange'] = exchange
                all_prices.append(symbol_data[['timestamp', 'exchange', 'bid', 'ask']])
                
        if len(all_prices) < 2:
            return opportunities
            
        # æ™‚é–“ç¯„å›²ã‚’30ç§’ã®çª“ã§åŒºåˆ‡ã£ã¦åˆ†æ
        all_data = pd.concat(all_prices, ignore_index=True)
        all_data = all_data.sort_values('timestamp')
        
        # 30ç§’çª“ã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        all_data['time_window'] = all_data['timestamp'].dt.floor('30S')
        
        for window, window_data in all_data.groupby('time_window'):
            if len(window_data) < 2:
                continue
                
            # æœ€é«˜bid ã¨æœ€ä½ask ã‚’è¦‹ã¤ã‘ã‚‹
            max_bid_row = window_data.loc[window_data['bid'].idxmax()]
            min_ask_row = window_data.loc[window_data['ask'].idxmin()]
            
            if max_bid_row['exchange'] != min_ask_row['exchange']:
                spread = max_bid_row['bid'] - min_ask_row['ask']
                spread_pct = (spread / min_ask_row['ask']) * 100
                
                if spread_pct >= min_spread_pct:
                    opportunities.append({
                        'timestamp': window.isoformat(),
                        'symbol': symbol,
                        'buy_exchange': min_ask_row['exchange'],
                        'sell_exchange': max_bid_row['exchange'],
                        'buy_price': float(min_ask_row['ask']),
                        'sell_price': float(max_bid_row['bid']),
                        'spread': float(spread),
                        'spread_pct': float(spread_pct)
                    })
                    
        return opportunities
        
    def generate_report(self, detailed: bool = False) -> str:
        """æ¤œè¨¼çµæœã®ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        logger.info("ğŸ“‹ æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­...")
        
        # å„æ¤œè¨¼ã‚’å®Ÿè¡Œ
        format_results = self.validate_data_format()
        price_results = self.validate_price_consistency() 
        timestamp_results = self.validate_timestamp_synchronization()
        arbitrage_results = self.find_arbitrage_opportunities()
        
        report_lines = [
            "=" * 80,
            "ğŸ“Š PRICE DATA VALIDATION REPORT",
            "=" * 80,
            f"ç”Ÿæˆæ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            f"å¯¾è±¡å–å¼•æ‰€: {', '.join(self.data_frames.keys())}",
            ""
        ]
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆçµæœ
        report_lines.extend([
            "ğŸ“‹ 1. ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¤œè¨¼",
            "-" * 40
        ])
        
        for exchange, result in format_results.items():
            status = "âœ…" if not result['missing_columns'] and result['duplicate_rows'] == 0 else "âš ï¸"
            report_lines.extend([
                f"{status} {exchange.upper()}:",
                f"  ç·è¡Œæ•°: {result['total_rows']:,}",
                f"  é‡è¤‡è¡Œ: {result['duplicate_rows']}",
                f"  æ¬ æã‚«ãƒ©ãƒ : {result['missing_columns'] if result['missing_columns'] else 'ãªã—'}"
            ])
            
            if detailed and result['null_counts']:
                report_lines.append("  NULLå€¤:")
                for col, count in result['null_counts'].items():
                    if count > 0:
                        report_lines.append(f"    {col}: {count}")
        
        report_lines.append("")
        
        # ä¾¡æ ¼æ•´åˆæ€§çµæœ
        report_lines.extend([
            "ğŸ’° 2. ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§",
            "-" * 40
        ])
        
        for exchange, result in price_results.items():
            issues = result['bid_ask_violations'] + result['zero_prices'] + result['negative_prices']
            status = "âœ…" if issues == 0 else "âš ï¸" if issues < 10 else "âŒ"
            
            report_lines.extend([
                f"{status} {exchange.upper()}:",
                f"  bid > ask é•å: {result['bid_ask_violations']}",
                f"  ã‚¼ãƒ­ä¾¡æ ¼: {result['zero_prices']}",
                f"  è² ã®ä¾¡æ ¼: {result['negative_prices']}",
                f"  æ¥µç«¯ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰(>5%): {result['extreme_spreads']}"
            ])
            
            if detailed and result['price_ranges']:
                report_lines.append("  ä¾¡æ ¼ãƒ¬ãƒ³ã‚¸:")
                for symbol, ranges in result['price_ranges'].items():
                    if ranges['count'] > 0:
                        report_lines.append(f"    {symbol}: BTC {ranges['bid_min']:.2f}-{ranges['bid_max']:.2f} ({ranges['count']}ä»¶)")
        
        report_lines.append("")
        
        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—åŒæœŸçµæœ
        if 'error' not in timestamp_results:
            report_lines.extend([
                "â° 3. ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—åŒæœŸæ€§",
                "-" * 40,
                f"ãƒ‡ãƒ¼ã‚¿æœŸé–“: {timestamp_results['time_range']['duration_hours']:.1f}æ™‚é–“",
                f"é–‹å§‹æ™‚åˆ»: {timestamp_results['time_range']['start']}",
                f"çµ‚äº†æ™‚åˆ»: {timestamp_results['time_range']['end']}",
                ""
            ])
            
            for exchange, coverage in timestamp_results['exchange_coverage'].items():
                report_lines.append(f"ğŸ“Š {exchange.upper()}: {coverage['data_points']:,}ç‚¹ (ã‚«ãƒãƒ¼ç‡: {coverage['coverage_ratio']*100:.1f}%)")
        
        report_lines.append("")
        
        # ã‚¢ãƒ¼ãƒ“ãƒˆãƒ©ãƒ¼ã‚¸æ©Ÿä¼šçµæœ
        report_lines.extend([
            "ğŸ¯ 4. ã‚¢ãƒ¼ãƒ“ãƒˆãƒ©ãƒ¼ã‚¸æ©Ÿä¼šåˆ†æ",
            "-" * 40,
            f"ç™ºè¦‹ã•ã‚ŒãŸæ©Ÿä¼š: {arbitrage_results['total_opportunities']}ä»¶",
            ""
        ])
        
        for symbol, stats in arbitrage_results['opportunities_by_symbol'].items():
            if stats['count'] > 0:
                report_lines.append(f"ğŸ’ {symbol}: {stats['count']}ä»¶ (å¹³å‡ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰: {stats['avg_spread']:.3f}%, æœ€å¤§: {stats['max_spread']:.3f}%)")
        
        if detailed and arbitrage_results['best_opportunities']:
            report_lines.extend([
                "",
                "ğŸ† ä¸Šä½ã‚¢ãƒ¼ãƒ“ãƒˆãƒ©ãƒ¼ã‚¸æ©Ÿä¼š:"
            ])
            for i, opp in enumerate(arbitrage_results['best_opportunities'][:5], 1):
                report_lines.append(
                    f"  {i}. {opp['symbol']}: {opp['spread_pct']:.3f}% "
                    f"({opp['sell_exchange']} ${opp['sell_price']:.2f} â†’ {opp['buy_exchange']} ${opp['buy_price']:.2f})"
                )
        
        report_lines.extend([
            "",
            "=" * 80
        ])
        
        return "\n".join(report_lines)


def main():
    parser = argparse.ArgumentParser(description="ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å“è³ªæ¤œè¨¼")
    parser.add_argument("--date", required=True, help="æ¤œè¨¼ã™ã‚‹æ—¥ä»˜ (ä¾‹: 20250623)")
    parser.add_argument("--data-dir", default="data/price_logs", help="ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹")
    parser.add_argument("--detailed", action="store_true", help="è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ")
    parser.add_argument("--output", help="ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«")
    
    args = parser.parse_args()
    
    try:
        validator = PriceDataValidator(args.data_dir)
        validator.load_csv_files(args.date)
        
        if not validator.data_frames:
            logger.error("âŒ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return 1
            
        report = validator.generate_report(detailed=args.detailed)
        
        if args.output:
            with open(args.output, 'w', encoding='utf-8') as f:
                f.write(report)
            logger.info(f"ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: {args.output}")
        else:
            print(report)
            
        return 0
        
    except Exception as e:
        logger.error(f"âŒ æ¤œè¨¼ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return 1


if __name__ == "__main__":
    exit(main())