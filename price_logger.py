#!/usr/bin/env python3
"""
price_logger.py
===============
ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ä¾¡æ ¼ãƒ­ã‚¬ãƒ¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€‚

è¤‡æ•°å–å¼•æ‰€ï¼ˆHyperliquid / Bybit / Binance / Gate.io / KuCoinï¼‰ã¨
è¤‡æ•°éŠ˜æŸ„ï¼ˆä¾‹: BTC, ETH, SOL ãªã©ï¼‰ã®Bid/Askä¾¡æ ¼ã‚’1ç§’é–“éš”ã§CSVã«è¨˜éŒ²ã—ã¾ã™ã€‚

* å–å¼•æ‰€å›ºæœ‰ã®WebSocketå®Ÿè£…ã¯ src/exchanges/ ä»¥ä¸‹ã«ã‚ã‚‹å„ã‚¯ãƒ©ã‚¹ã‚’å†åˆ©ç”¨
* å–å¾—é–“éš”ã¯ LOG_INTERVAL ã§åˆ¶å¾¡
* ãƒ•ã‚¡ã‚¤ãƒ«ã¯æ—¥ä»˜ã”ã¨ã€å–å¼•æ‰€ã”ã¨ã«è‡ªå‹•ãƒ­ãƒ¼ãƒ†ãƒ¼ãƒˆ
* åœ§ç¸®ã‚ªãƒ—ã‚·ãƒ§ãƒ³å¯¾å¿œï¼ˆ--compressï¼‰

ä½¿ã„æ–¹
------
```bash
python price_logger.py --symbols BTC ETH SOL
python price_logger.py --symbols BTC ETH SOL --compress --interval 0.5
```
"""

import asyncio
import csv
import gzip
import logging
from logging.handlers import RotatingFileHandler
import psutil
import signal
import sys
import time
import traceback
from argparse import ArgumentParser
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List, Any
from collections import defaultdict

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from src.exchanges.hyperliquid import HyperliquidExchange
from src.exchanges.bybit import BybitExchange
from src.exchanges.binance import BinanceExchange
from src.exchanges.gateio import GateioExchange
from src.exchanges.bitget import BitgetExchange
from src.exchanges.kucoin import KuCoinExchange
from src.core.config import get_config
from src.interfaces.exchange import Ticker

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ã‚¨ãƒ©ãƒ¼å°‚ç”¨ãƒ­ã‚°ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’è¿½åŠ 
logs_dir = Path("logs")
logs_dir.mkdir(exist_ok=True)

error_handler = RotatingFileHandler(
    logs_dir / "price_logger_errors.log",
    maxBytes=10*1024*1024,  # 10MB
    backupCount=5
)
error_handler.setLevel(logging.ERROR)
error_handler.setFormatter(logging.Formatter(
    '%(asctime)s - %(name)s - %(levelname)s - [%(funcName)s:%(lineno)d] %(message)s'
))

# ã‚¨ãƒ©ãƒ¼å°‚ç”¨ãƒ­ã‚¬ãƒ¼
error_logger = logging.getLogger('price_logger.errors')
error_logger.addHandler(error_handler)
error_logger.setLevel(logging.ERROR)


class PriceLogger:
    """å„å–å¼•æ‰€ã®ä¾¡æ ¼ã‚’CSVã«è¨˜éŒ²ã™ã‚‹ã‚¯ãƒ©ã‚¹"""

    def __init__(self, exchanges: Dict[str, Any], symbols: List[str], 
                 log_interval: float = 1.0, compress: bool = False, 
                 price_threshold: float = None):
        """
        Args:
            exchanges: å–å¼•æ‰€åã¨ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®è¾æ›¸
            symbols: ç›£è¦–å¯¾è±¡ã‚·ãƒ³ãƒœãƒ«ãƒªã‚¹ãƒˆ
            log_interval: ãƒ­ã‚°è¨˜éŒ²é–“éš”ï¼ˆç§’ï¼‰
            compress: gzipåœ§ç¸®ã‚’ä½¿ç”¨ã™ã‚‹ã‹
            price_threshold: ä¾¡æ ¼å¤‰æ›´æ¤œå‡ºã—ãã„å€¤ï¼ˆCLIã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        """
        self.exchanges = exchanges
        self.symbols = symbols
        self.log_interval = log_interval
        self.compress = compress
        self.custom_price_threshold = price_threshold
        
        # è¨­å®šèª­ã¿è¾¼ã¿
        self.config = get_config()
        
        # ä¾¡æ ¼æ›´æ–°ã‚­ãƒ¥ãƒ¼ï¼ˆé«˜é »åº¦æ›´æ–°å¯¾å¿œï¼‰
        self.price_queue = asyncio.Queue(maxsize=200000)  # 2å€ã«æ‹¡å¤§
        
        # CSVæ›¸ãè¾¼ã¿å°‚ç”¨ã‚­ãƒ¥ãƒ¼ï¼ˆCSVå‡¦ç†ã‚’åˆ†é›¢ï¼‰
        self.csv_queue = asyncio.Queue(maxsize=20000)  # 2å€ã«æ‹¡å¤§
        
        # æœ€æ–°ä¾¡æ ¼ã‚’ä¿å­˜ {exchange: {symbol: Ticker}}
        self.latest_prices: Dict[str, Dict[str, Ticker]] = {
            name: {} for name in exchanges.keys()
        }
        
        # å‰å›è¨˜éŒ²ä¾¡æ ¼ï¼ˆå·®åˆ†è¨˜éŒ²ç”¨ï¼‰
        self.last_saved_prices: Dict[str, Dict[str, Ticker]] = {
            name: {} for name in exchanges.keys()
        }
        
        # çµ±è¨ˆæƒ…å ±
        self.stats = {
            "total_updates": 0,
            "updates_per_exchange": defaultdict(int),
            "start_time": None,
            "last_save_time": None,
            "queue_size": 0,
            "memory_mb": 0,
            "cpu_percent": 0.0
        }
        
        # CSVãƒ©ã‚¤ã‚¿ãƒ¼ç®¡ç† {exchange: {"file": file_handle, "writer": csv.writer}}
        self.csv_handlers: Dict[str, Dict[str, Any]] = {}
        self.current_date = None
        self.last_flush_time = datetime.now()
        
        # psutil CPUç›£è¦–ç”¨
        self.process = psutil.Process()
        # åˆå›CPUè¨ˆæ¸¬ï¼ˆå¾Œç¶šã®è¨ˆæ¸¬ã‚’å®‰å®šã•ã›ã‚‹ï¼‰
        self.process.cpu_percent(interval=None)
        
        # åˆ¶å¾¡ãƒ•ãƒ©ã‚°
        self.shutdown_event = asyncio.Event()
        self.tasks = []
        
        # ã‚­ãƒ¥ãƒ¼æº€æ¯è­¦å‘Šã®åˆ¶é™ï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™ï¼‰
        self.last_queue_full_warning = 0
        self.queue_full_warning_interval = 5  # 5ç§’ã«1å›ã¾ã§
        
        # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ç”¨ãƒ¡ã‚½ãƒƒãƒ‰
        self.error_logger = error_logger
        
        # ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ç™»éŒ²
        self._setup_signal_handlers()
    
    def log_error(self, error_type: str, exchange: str = "", symbol: str = "", 
                  message: str = "", exception: Exception = None):
        """ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’è¨˜éŒ²ã™ã‚‹"""
        try:
            error_msg = f"[{error_type}]"
            if exchange:
                error_msg += f" Exchange: {exchange}"
            if symbol:
                error_msg += f" Symbol: {symbol}"
            if message:
                error_msg += f" Message: {message}"
            
            # ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹æƒ…å ±ã‚’è¿½åŠ 
            error_msg += f" | Queue: {self.price_queue.qsize()}"
            error_msg += f" | Memory: {self.stats.get('memory_mb', 0):.1f}MB"
            error_msg += f" | CPU: {self.stats.get('cpu_percent', 0):.1f}%"
            error_msg += f" | Updates: {self.stats.get('total_updates', 0)}"
            
            if exception:
                error_msg += f" | Exception: {str(exception)}"
                self.error_logger.error(error_msg, exc_info=True)
            else:
                self.error_logger.error(error_msg)
                
        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°è‡ªä½“ãŒã‚¨ãƒ©ãƒ¼ã—ãŸå ´åˆã®æœ€ä½é™ã®å‡¦ç†
            print(f"Error logging failed: {e}")
            logger.error(f"Error logging failed: {e}")
        
    def _get_output_path(self, exchange: str, date_str: str) -> Path:
        """å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ç”Ÿæˆ"""
        output_dir = Path("data") / "price_logs" / date_str
        output_dir.mkdir(parents=True, exist_ok=True)
        
        filename = f"{exchange.lower()}_prices_{date_str}.csv"
        if self.compress:
            filename += ".gz"
            
        return output_dir / filename
        
    def _init_csv_writers(self) -> None:
        """CSVãƒ©ã‚¤ã‚¿ãƒ¼ã‚’åˆæœŸåŒ–"""
        current_date = datetime.now(timezone.utc).strftime("%Y%m%d")
        
        # æ—¥ä»˜ãŒå¤‰ã‚ã£ãŸå ´åˆã¯æ—¢å­˜ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‰ã˜ã‚‹
        if self.current_date and self.current_date != current_date:
            self._close_csv_writers()
            # 24æ™‚é–“ãƒ­ãƒ¼ãƒ†ãƒ¼ãƒˆæ™‚ã« last_saved_prices ã‚’ã‚¯ãƒªã‚¢ï¼ˆãƒ¡ãƒ¢ãƒªç¯€ç´„ï¼‰
            self.last_saved_prices.clear()
            for exchange in self.exchanges.keys():
                self.last_saved_prices[exchange] = {}
            logger.info("ğŸ”„ æ—¥ä»˜å¤‰æ›´ã«ã‚ˆã‚Šå‰å›è¨˜éŒ²ä¾¡æ ¼ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")
            
        self.current_date = current_date
        
        for exchange in self.exchanges.keys():
            if exchange in self.csv_handlers:
                continue
                
            csv_path = self._get_output_path(exchange, current_date)
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã
            if self.compress:
                file_handle = gzip.open(csv_path, "at", encoding="utf-8", newline="")
            else:
                file_handle = open(csv_path, "a", encoding="utf-8", newline="", buffering=1)
                
            writer = csv.writer(file_handle)
            
            # æ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’æ›¸ã
            if csv_path.stat().st_size == 0:
                writer.writerow([
                    "timestamp", "exchange", "symbol", 
                    "bid", "ask", "bid_size", "ask_size",
                    "last", "mark_price", "volume_24h"
                ])
                
            self.csv_handlers[exchange] = {
                "file": file_handle,
                "writer": writer
            }
            
    def _close_csv_writers(self) -> None:
        """CSVãƒ©ã‚¤ã‚¿ãƒ¼ã‚’é–‰ã˜ã‚‹"""
        for handler in self.csv_handlers.values():
            try:
                handler["file"].close()
            except Exception as e:
                logger.error(f"Failed to close file: {e}")
                
        self.csv_handlers.clear()
        
    async def price_callback(self, exchange_name: str, ticker: Ticker) -> None:
        """ä¾¡æ ¼æ›´æ–°ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆã‚­ãƒ¥ãƒ¼ã«æŠ•å…¥ï¼‰"""
        try:
            # ã‚­ãƒ¥ãƒ¼ã«ä¾¡æ ¼æ›´æ–°ã‚’æŠ•å…¥ï¼ˆéåŒæœŸã§ãƒ–ãƒ­ãƒƒã‚¯ã—ãªã„ï¼‰
            self.price_queue.put_nowait((exchange_name, ticker))
            
            # çµ±è¨ˆæ›´æ–°
            self.stats["total_updates"] += 1
            self.stats["updates_per_exchange"][exchange_name] += 1
            self.stats["queue_size"] = self.price_queue.qsize()
            
        except asyncio.QueueFull:
            # ã‚­ãƒ¥ãƒ¼ãŒæº€æ¯ã®å ´åˆã¯è­¦å‘Šã—ã¦ã‚¹ã‚­ãƒƒãƒ—ï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™ä»˜ãï¼‰
            current_time = time.time()
            if current_time - self.last_queue_full_warning > self.queue_full_warning_interval:
                logger.warning(f"âš ï¸ ä¾¡æ ¼æ›´æ–°ã‚­ãƒ¥ãƒ¼ãŒæº€æ¯ã§ã™ - ä¸€éƒ¨ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ã‚­ãƒƒãƒ—ä¸­... (ã‚­ãƒ¥ãƒ¼ã‚µã‚¤ã‚º: {self.price_queue.qsize()})")
                self.log_error("QUEUE_FULL", exchange_name, ticker.symbol, 
                             f"ã‚­ãƒ¥ãƒ¼ãŒæº€æ¯ã§ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ã‚­ãƒƒãƒ—")
                self.last_queue_full_warning = current_time
            
    async def _price_consumer(self) -> None:
        """ä¾¡æ ¼æ›´æ–°ã‚­ãƒ¥ãƒ¼ã®æ¶ˆè²»è€…ï¼ˆé©å¿œçš„ãƒãƒƒãƒå‡¦ç†ï¼‰"""
        base_batch_size = 500   # å¤§å¹…ã«æ‹¡å¤§
        max_batch_size = 2000   # ã•ã‚‰ã«å¤§ãã
        min_timeout = 0.0005    # ã‚ˆã‚ŠçŸ­ã„ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆ0.5msï¼‰
        max_timeout = 0.1       # 100ms
        
        # é©å¿œçš„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        current_batch_size = base_batch_size
        current_timeout = min_timeout
        
        while not self.shutdown_event.is_set():
            try:
                batch = []
                
                # ãƒãƒƒãƒã‚’åé›†ï¼ˆé©å¿œçš„ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼‰
                end_time = asyncio.get_event_loop().time() + current_timeout
                
                while len(batch) < current_batch_size and asyncio.get_event_loop().time() < end_time:
                    try:
                        remaining_time = max(0, end_time - asyncio.get_event_loop().time())
                        exchange_name, ticker = await asyncio.wait_for(
                            self.price_queue.get(), timeout=remaining_time
                        )
                        batch.append((exchange_name, ticker))
                        
                    except asyncio.TimeoutError:
                        break
                        
                # ãƒãƒƒãƒå‡¦ç†
                if batch:
                    for exchange_name, ticker in batch:
                        # æœ€æ–°ä¾¡æ ¼ã‚’æ›´æ–°
                        if exchange_name not in self.latest_prices:
                            self.latest_prices[exchange_name] = {}
                        self.latest_prices[exchange_name][ticker.symbol] = ticker
                        
                        # ã‚­ãƒ¥ãƒ¼ã‚¿ã‚¹ã‚¯ã‚’å®Œäº†
                        self.price_queue.task_done()
                    
                    # é©å¿œçš„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´
                    queue_size = self.price_queue.qsize()
                    if queue_size > 1000:  # é«˜è² è·æ™‚ï¼ˆé–¾å€¤ã‚’ä¸Šã’ã‚‹ï¼‰
                        current_batch_size = min(max_batch_size, current_batch_size + 20)
                        current_timeout = min(max_timeout, current_timeout * 1.1)
                    elif queue_size < 100:  # ä½è² è·æ™‚
                        current_batch_size = max(base_batch_size, current_batch_size - 10)
                        current_timeout = max(min_timeout, current_timeout * 0.95)
                
                # CPUã‚’ä»–ã‚¿ã‚¹ã‚¯ã«è­²ã‚‹ï¼ˆidleæ™‚ã¯ç„¡é§„ãªsleepã‚’é¿ã‘ã‚‹ï¼‰
                await asyncio.sleep(0)
                
            except Exception as e:
                logger.error(f"ä¾¡æ ¼æ¶ˆè²»è€…ã‚¨ãƒ©ãƒ¼: {e}")
                self.log_error("PRICE_CONSUMER_ERROR", "", "", 
                             f"ä¾¡æ ¼æ¶ˆè²»è€…ã§ã‚¨ãƒ©ãƒ¼", e)
                await asyncio.sleep(1)
        
    def _has_price_changed(self, exchange: str, symbol: str, ticker: Ticker) -> bool:
        """ä¾¡æ ¼ãŒå‰å›è¨˜éŒ²ã‹ã‚‰å¤‰åŒ–ã—ãŸã‹ãƒã‚§ãƒƒã‚¯ï¼ˆå·®åˆ†è¨˜éŒ²ï¼‰"""
        if exchange not in self.last_saved_prices:
            return True
        if symbol not in self.last_saved_prices[exchange]:
            return True
            
        last_ticker = self.last_saved_prices[exchange][symbol]
        
        # bid/askãŒNoneã®å ´åˆã¯å¤‰åŒ–ã‚ã‚Šã¨ã—ã¦è¨˜éŒ²
        if ticker.bid is None or ticker.ask is None:
            return True
        if last_ticker.bid is None or last_ticker.ask is None:
            return True
        
        # ä¾¡æ ¼å¤‰æ›´ã—ãã„å€¤ã‚’å–å¾—ï¼ˆCLI > config > ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ ã®å„ªå…ˆé †ä½ï¼‰
        threshold = (self.custom_price_threshold or 
                    self.config.get('price_logger.price_change_threshold', 0.00001))  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ0.001%
        
        # bid/askã®å¤‰åŒ–ã‚’ãƒã‚§ãƒƒã‚¯
        if (abs(float(ticker.bid) - float(last_ticker.bid)) / float(last_ticker.bid)) > threshold:
            return True
        if (abs(float(ticker.ask) - float(last_ticker.ask)) / float(last_ticker.ask)) > threshold:
            return True
            
        return False

    async def _save_prices_periodically(self) -> None:
        """å®šæœŸçš„ã«ä¾¡æ ¼ã‚’CSVã‚­ãƒ¥ãƒ¼ã«é€ä¿¡ï¼ˆå·®åˆ†è¨˜éŒ²å¯¾å¿œï¼‰"""
        while not self.shutdown_event.is_set():
            try:
                await asyncio.sleep(self.log_interval)
                
                # ç¾åœ¨æ™‚åˆ»
                timestamp = datetime.now(timezone.utc).isoformat()
                
                # å„å–å¼•æ‰€ã®ä¾¡æ ¼ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦CSVã‚­ãƒ¥ãƒ¼ã«é€ä¿¡ï¼ˆå·®åˆ†ã®ã¿ï¼‰
                csv_items = []
                for exchange_name, prices in self.latest_prices.items():
                    for symbol, ticker in prices.items():
                        # ä¾¡æ ¼å¤‰åŒ–ã‚’ãƒã‚§ãƒƒã‚¯
                        if self._has_price_changed(exchange_name, symbol, ticker):
                            # CSVã‚­ãƒ¥ãƒ¼ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
                            csv_data = {
                                "timestamp": timestamp,
                                "exchange": exchange_name,
                                "symbol": symbol,
                                "ticker": ticker
                            }
                            csv_items.append(csv_data)
                            
                            # è¨˜éŒ²æ¸ˆã¿ä¾¡æ ¼ã‚’æ›´æ–°
                            if exchange_name not in self.last_saved_prices:
                                self.last_saved_prices[exchange_name] = {}
                            self.last_saved_prices[exchange_name][symbol] = ticker
                
                # CSVã‚­ãƒ¥ãƒ¼ã«é€ä¿¡ï¼ˆãƒãƒ³ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ï¼‰
                for csv_data in csv_items:
                    try:
                        self.csv_queue.put_nowait(csv_data)
                    except asyncio.QueueFull:
                        logger.warning(f"âš ï¸ CSVã‚­ãƒ¥ãƒ¼ãŒæº€æ¯ã§ã™ - ä¸€éƒ¨ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ã‚­ãƒƒãƒ—ä¸­... (ã‚­ãƒ¥ãƒ¼ã‚µã‚¤ã‚º: {self.csv_queue.qsize()})")
                        self.log_error("CSV_QUEUE_FULL", csv_data["exchange"], csv_data["symbol"], 
                                     f"CSVã‚­ãƒ¥ãƒ¼ãŒæº€æ¯ã§ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ã‚­ãƒƒãƒ—")
                        break
                
                # çµ±è¨ˆæ›´æ–°
                self.stats["last_save_time"] = timestamp
                
                # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆ5åˆ†ã”ã¨ï¼‰
                if int(datetime.now().timestamp()) % 300 == 0:
                    # latest_pricesã‚’ã‚¯ãƒªã‚¢ï¼ˆãƒ¡ãƒ¢ãƒªç¯€ç´„ï¼‰
                    for exchange_prices in self.latest_prices.values():
                        exchange_prices.clear()
                
                # ãƒ­ã‚°å‡ºåŠ›ï¼ˆ5ç§’ã”ã¨ï¼‰
                if int(datetime.now().timestamp()) % 5 == 0:
                    elapsed = datetime.now() - self.stats["start_time"]
                    
                    # ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡ã‚’æ›´æ–°
                    self.stats["memory_mb"] = self.process.memory_info().rss / 1024 / 1024
                    self.stats["cpu_percent"] = self.process.cpu_percent()
                    
                    logger.info(
                        f"ğŸ“Š è¨˜éŒ²ä¸­: {len(csv_items)}ä»¶é€ä¿¡ | "
                        f"ç·æ›´æ–°: {self.stats['total_updates']:,}å› | "
                        f"ã‚­ãƒ¥ãƒ¼: {self.stats['queue_size']} | "
                        f"CSVã‚­ãƒ¥ãƒ¼: {self.csv_queue.qsize()} | "
                        f"ãƒ¡ãƒ¢ãƒª: {self.stats['memory_mb']:.1f}MB | "
                        f"CPU: {self.stats['cpu_percent']:.1f}% | "
                        f"çµŒé: {elapsed.seconds}ç§’"
                    )
                    
            except Exception as e:
                logger.error(f"ä¾¡æ ¼ä¿å­˜ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}")
                self.log_error("PRICE_SCHEDULER_ERROR", "", "", 
                             f"ä¾¡æ ¼ä¿å­˜ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã§ã‚¨ãƒ©ãƒ¼", e)
                await asyncio.sleep(1)
    
    async def _csv_writer_worker(self) -> None:
        """CSVæ›¸ãè¾¼ã¿å°‚ç”¨ãƒ¯ãƒ¼ã‚«ãƒ¼ï¼ˆåˆ¥ã‚­ãƒ¥ãƒ¼ã§å‡¦ç†ï¼‰"""
        batch_size = 500  # CSVãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å¤§å¹…æ‹¡å¤§
        timeout = 0.2     # CSVãƒãƒƒãƒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’çŸ­ç¸®
        
        while not self.shutdown_event.is_set():
            try:
                batch = []
                
                # ãƒãƒƒãƒã‚’åé›†
                end_time = asyncio.get_event_loop().time() + timeout
                
                while len(batch) < batch_size and asyncio.get_event_loop().time() < end_time:
                    try:
                        remaining_time = max(0, end_time - asyncio.get_event_loop().time())
                        csv_data = await asyncio.wait_for(
                            self.csv_queue.get(), timeout=remaining_time
                        )
                        batch.append(csv_data)
                        
                    except asyncio.TimeoutError:
                        break
                
                # ãƒãƒƒãƒã‚’CSVã«æ›¸ãè¾¼ã¿
                if batch:
                    # CSVãƒ©ã‚¤ã‚¿ãƒ¼ã‚’åˆæœŸåŒ–ï¼ˆæ—¥ä»˜ãƒ­ãƒ¼ãƒ†ãƒ¼ãƒˆå¯¾å¿œï¼‰
                    self._init_csv_writers()
                    
                    # ãƒãƒƒãƒæ›¸ãè¾¼ã¿
                    for csv_data in batch:
                        exchange_name = csv_data["exchange"]
                        
                        if exchange_name not in self.csv_handlers:
                            continue
                            
                        writer = self.csv_handlers[exchange_name]["writer"]
                        ticker = csv_data["ticker"]
                        
                        # ãƒ‡ãƒ¼ã‚¿è¡Œã‚’ä½œæˆ
                        row = [
                            csv_data["timestamp"],
                            exchange_name,
                            csv_data["symbol"],
                            float(ticker.bid) if ticker.bid else "",
                            float(ticker.ask) if ticker.ask else "",
                            "",  # bid_size (å°†æ¥ã®æ‹¡å¼µç”¨)
                            "",  # ask_size (å°†æ¥ã®æ‹¡å¼µç”¨)
                            float(ticker.last) if ticker.last else "",
                            float(ticker.mark_price) if ticker.mark_price else "",
                            float(ticker.volume_24h) if ticker.volume_24h else ""
                        ]
                        
                        writer.writerow(row)
                        self.csv_queue.task_done()
                    
                    # å®šæœŸçš„ã«ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ï¼ˆåœ§ç¸®æ™‚ã¯60ç§’ã€éåœ§ç¸®æ™‚ã¯30ç§’ï¼‰
                    now = datetime.now()
                    flush_interval = (self.config.get('price_logger.gzip_flush_interval', 60) 
                                    if self.compress else 30)
                    
                    if (now - self.last_flush_time).seconds >= flush_interval:
                        for handler in self.csv_handlers.values():
                            handler["file"].flush()
                        self.last_flush_time = now
                
                # CPUã‚’ä»–ã‚¿ã‚¹ã‚¯ã«è­²ã‚‹
                await asyncio.sleep(0)
                
            except Exception as e:
                logger.error(f"CSVãƒ©ã‚¤ã‚¿ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}")
                self.log_error("CSV_WRITER_ERROR", "", "", 
                             f"CSVãƒ©ã‚¤ã‚¿ãƒ¼ã§ã‚¨ãƒ©ãƒ¼", e)
                await asyncio.sleep(1)
                
    async def connect_all_exchanges(self) -> bool:
        """å…¨å–å¼•æ‰€ã«ä¸¦åˆ—æ¥ç¶š"""
        logger.info("ğŸš€ å–å¼•æ‰€ã¸ã®ä¸¦åˆ—æ¥ç¶šã‚’é–‹å§‹...")
        
        # ä¾¡æ ¼æ¶ˆè²»è€…ã‚¿ã‚¹ã‚¯ã‚’é–‹å§‹
        self.consumer_task = asyncio.create_task(self._price_consumer())
        
        # CSVãƒ©ã‚¤ã‚¿ãƒ¼ã‚¿ã‚¹ã‚¯ã‚’é–‹å§‹
        self.csv_writer_task = asyncio.create_task(self._csv_writer_worker())
        
        # ä¾¡æ ¼ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’äº‹å‰ç™»éŒ²ï¼ˆãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–ï¼‰
        for name, exchange in self.exchanges.items():
            # å¼±å‚ç…§ã‚’ä½¿ã£ã¦ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã‚’é˜²ã
            def create_callback(exchange_name: str):
                async def callback(_: str, ticker: Ticker):
                    await self.price_callback(exchange_name, ticker)
                return callback
            
            exchange.add_price_callback(create_callback(name))
        
        # ä¸¦åˆ—æ¥ç¶šï¼ˆé«˜é€ŸåŒ–ï¼‰
        connection_tasks = [
            self._connect_single_exchange(name, exchange) 
            for name, exchange in self.exchanges.items()
        ]
        
        connection_results = await asyncio.gather(*connection_tasks, return_exceptions=True)
        
        # çµæœã‚’é›†è¨ˆ
        connected = []
        for name, result in zip(self.exchanges.keys(), connection_results):
            if isinstance(result, Exception):
                logger.error(f"âŒ {name} æ¥ç¶šã‚¨ãƒ©ãƒ¼: {result}")
            elif result:
                connected.append(name)
                logger.info(f"âœ… {name} æ¥ç¶šæˆåŠŸ")
            else:
                logger.warning(f"âŒ {name} æ¥ç¶šå¤±æ•—")
                
        success_rate = len(connected) / len(self.exchanges) * 100
        logger.info(f"ğŸ“Š æ¥ç¶šçµæœ: {len(connected)}/{len(self.exchanges)}å–å¼•æ‰€ ({success_rate:.0f}%)")
        
        return len(connected) >= 3  # æœ€ä½3å–å¼•æ‰€ã¯æ¥ç¶šå¿…è¦
        
    async def _connect_single_exchange(self, name: str, exchange: Any) -> bool:
        """å˜ä¸€å–å¼•æ‰€ã¸ã®æ¥ç¶šï¼ˆæŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ä»˜ãå†è©¦è¡Œï¼‰"""
        max_retries = 3
        base_delay = 1.0
        
        for attempt in range(max_retries + 1):
            try:
                await exchange.connect_websocket(self.symbols)
                if exchange.is_connected:
                    return True
                    
            except Exception as e:
                if attempt == max_retries:
                    logger.error(f"âŒ {name} æœ€å¤§å†è©¦è¡Œå›æ•°ã«é”ã—ã¾ã—ãŸ: {e}")
                    self.log_error("CONNECTION_FAILED", name, "", 
                                 f"æœ€å¤§å†è©¦è¡Œå›æ•°ã«é”ã—ã¾ã—ãŸ", e)
                    return False
                    
                # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•
                delay = base_delay * (2 ** attempt)
                logger.warning(f"âš ï¸ {name} æ¥ç¶šå¤±æ•— (è©¦è¡Œ {attempt + 1}/{max_retries + 1}) - {delay}ç§’å¾Œã«å†è©¦è¡Œ: {e}")
                if attempt == 0:  # åˆå›ã‚¨ãƒ©ãƒ¼ã®ã¿ãƒ­ã‚°ã«è¨˜éŒ²
                    self.log_error("CONNECTION_RETRY", name, "", 
                                 f"æ¥ç¶šå¤±æ•—ã€å†è©¦è¡Œä¸­", e)
                await asyncio.sleep(delay)
                
        return False
        
    async def disconnect_all_exchanges(self) -> None:
        """å…¨å–å¼•æ‰€ã‹ã‚‰åˆ‡æ–­"""
        logger.info("ğŸ”Œ å…¨å–å¼•æ‰€ã‹ã‚‰åˆ‡æ–­ä¸­...")
        
        for name, exchange in self.exchanges.items():
            try:
                if exchange.is_connected:
                    await exchange.disconnect_websocket()
                    logger.info(f"âœ… {name} åˆ‡æ–­å®Œäº†")
            except Exception as e:
                logger.error(f"âš ï¸ {name} åˆ‡æ–­ã‚¨ãƒ©ãƒ¼: {e}")
                
    async def run(self) -> None:
        """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œãƒ«ãƒ¼ãƒ—"""
        self.stats["start_time"] = datetime.now()
        
        # å…¨å–å¼•æ‰€ã«æ¥ç¶š
        if not await self.connect_all_exchanges():
            raise Exception("å–å¼•æ‰€ã¸ã®æ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸ")
            
        # ä¾¡æ ¼ä¿å­˜ã‚¿ã‚¹ã‚¯ã‚’é–‹å§‹
        self.save_task = asyncio.create_task(self._save_prices_periodically())
        
        logger.info(f"ğŸ“Š ä¾¡æ ¼è¨˜éŒ²é–‹å§‹: {len(self.symbols)}ã‚·ãƒ³ãƒœãƒ« Ã— {len(self.exchanges)}å–å¼•æ‰€")
        logger.info(f"ğŸ’¾ ä¿å­˜é–“éš”: {self.log_interval}ç§’ | åœ§ç¸®: {'ON' if self.compress else 'OFF'}")
        logger.info("ğŸ“ˆ è¨˜éŒ²ã‚’åœæ­¢ã™ã‚‹ã«ã¯ Ctrl+C ã‚’æŠ¼ã—ã¦ãã ã•ã„")
        
        try:
            # ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³ã‚¤ãƒ™ãƒ³ãƒˆã‚’å¾…æ©Ÿ
            await self.shutdown_event.wait()
            
        except asyncio.CancelledError:
            pass
            
        finally:
            await self._cleanup()
            
            # æœ€çµ‚çµ±è¨ˆã‚’è¡¨ç¤º
            elapsed = datetime.now() - self.stats["start_time"]
            logger.info("=" * 60)
            logger.info("ğŸ“Š ä¾¡æ ¼è¨˜éŒ²çµ±è¨ˆ:")
            logger.info(f"â±ï¸ è¨˜éŒ²æ™‚é–“: {elapsed}")
            logger.info(f"ğŸ“ˆ ç·æ›´æ–°æ•°: {self.stats['total_updates']:,}å›")
            
            for exchange, count in self.stats["updates_per_exchange"].items():
                percentage = count / self.stats["total_updates"] * 100 if self.stats["total_updates"] > 0 else 0
                logger.info(f"   {exchange}: {count:,}å› ({percentage:.1f}%)")
                
            logger.info("=" * 60)
            
    def _setup_signal_handlers(self) -> None:
        """ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’è¨­å®š"""
        import signal
        
        def signal_handler(signum, _):
            logger.info(f"ğŸ›‘ ã‚·ã‚°ãƒŠãƒ« {signum} ã‚’å—ä¿¡ - æ­£å¸¸çµ‚äº†å‡¦ç†ã‚’é–‹å§‹...")
            asyncio.create_task(self._shutdown())
            
        # SIGINTã¨SIGTERMã‚’ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
        signal.signal(signal.SIGINT, signal_handler)
        signal.signal(signal.SIGTERM, signal_handler)
        
    async def _shutdown(self) -> None:
        """æ­£å¸¸çµ‚äº†å‡¦ç†"""
        logger.info("ğŸ”„ ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³å‡¦ç†ã‚’é–‹å§‹...")
        self.shutdown_event.set()
        
    async def _cleanup(self) -> None:
        """ãƒªã‚½ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        logger.info("ğŸ§¹ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å‡¦ç†ã‚’é–‹å§‹...")
        
        # ä¾¡æ ¼æ¶ˆè²»è€…ã‚¿ã‚¹ã‚¯ã‚’åœæ­¢
        if hasattr(self, 'consumer_task') and self.consumer_task:
            self.consumer_task.cancel()
            try:
                await self.consumer_task
            except asyncio.CancelledError:
                pass
        
        # CSVãƒ©ã‚¤ã‚¿ãƒ¼ã‚¿ã‚¹ã‚¯ã‚’åœæ­¢
        if hasattr(self, 'csv_writer_task') and self.csv_writer_task:
            self.csv_writer_task.cancel()
            try:
                await self.csv_writer_task
            except asyncio.CancelledError:
                pass
        
        # ä¾¡æ ¼ä¿å­˜ã‚¿ã‚¹ã‚¯ã‚’åœæ­¢
        if hasattr(self, 'save_task') and self.save_task:
            self.save_task.cancel()
            try:
                await self.save_task
            except asyncio.CancelledError:
                pass
                
        # å–å¼•æ‰€ã‹ã‚‰åˆ‡æ–­
        await self.disconnect_all_exchanges()
        
        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‰ã˜ã‚‹
        self._close_csv_writers()
        
        logger.info("âœ… ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")


def parse_args():
    """ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‚’ãƒ‘ãƒ¼ã‚¹"""
    parser = ArgumentParser(description="ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ä¾¡æ ¼ãƒ­ã‚¬ãƒ¼ï¼ˆè¤‡æ•°å–å¼•æ‰€å¯¾å¿œï¼‰")
    parser.add_argument(
        "--symbols", 
        nargs="+", 
        default=["BTC", "ETH", "SOL"],
        help="ç›£è¦–ã™ã‚‹ã‚·ãƒ³ãƒœãƒ« (ä¾‹: BTC ETH SOL)"
    )
    parser.add_argument(
        "--interval",
        type=float,
        default=1.0,
        help="è¨˜éŒ²é–“éš”ï¼ˆç§’ï¼‰ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1.0"
    )
    parser.add_argument(
        "--compress",
        action="store_true",
        help="gzipåœ§ç¸®ã‚’ä½¿ç”¨"
    )
    parser.add_argument(
        "--exchanges",
        nargs="+",
        default=["Hyperliquid", "Bybit", "Gateio", "KuCoin"],
        help="ä½¿ç”¨ã™ã‚‹å–å¼•æ‰€"
    )
    parser.add_argument(
        "--price-threshold",
        type=float,
        help="ä¾¡æ ¼å¤‰æ›´æ¤œå‡ºã—ãã„å€¤ (ä¾‹: 0.0001 = 0.01%%)"
    )
    
    return parser.parse_args()


async def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    args = parse_args()
    
    # åˆ©ç”¨å¯èƒ½ãªå–å¼•æ‰€
    available_exchanges = {
        "Hyperliquid": HyperliquidExchange,
        "Bybit": BybitExchange,
        "Binance": BinanceExchange,
        "Gateio": GateioExchange,
        "Bitget": BitgetExchange,
        "KuCoin": KuCoinExchange
    }
    
    # æŒ‡å®šã•ã‚ŒãŸå–å¼•æ‰€ã®ã¿ä½¿ç”¨
    exchanges = {}
    for name in args.exchanges:
        if name in available_exchanges:
            exchanges[name] = available_exchanges[name]()
        else:
            logger.warning(f"âš ï¸ ä¸æ˜ãªå–å¼•æ‰€: {name}")
            
    if not exchanges:
        logger.error("âŒ æœ‰åŠ¹ãªå–å¼•æ‰€ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return
        
    # ä¾¡æ ¼ãƒ­ã‚¬ãƒ¼ã‚’ä½œæˆ
    price_logger = PriceLogger(
        exchanges=exchanges,
        symbols=args.symbols,
        log_interval=args.interval,
        compress=args.compress,
        price_threshold=args.price_threshold
    )
    
    try:
        await price_logger.run()
        
    except KeyboardInterrupt:
        logger.info("ğŸ‘‹ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚‹ä¸­æ–­...")
        
    except Exception as e:
        logger.error(f"ğŸ’¥ ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        pass